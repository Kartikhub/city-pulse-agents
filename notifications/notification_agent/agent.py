# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import asyncio
import json
import datetime
import re
from typing import Dict, List, Any, Optional
from collections import defaultdict, Counter
import numpy as np
from dataclasses import dataclass
import firebase_admin
from firebase_admin import credentials, messaging
from google.adk import Agent
from google.adk.agents.remote_a2a_agent import AGENT_CARD_WELL_KNOWN_PATH
from google.adk.agents.remote_a2a_agent import RemoteA2aAgent
from google.genai import types


@dataclass
class UserProfile:
    """User profile for personalized notifications"""
    user_id: str
    location: str
    interests: List[str]
    notification_preferences: Dict[str, bool]
    device_token: str


@dataclass
class EventCluster:
    """Represents a cluster of related events"""
    event_type: str
    location: str
    count: int
    severity: str
    time_window: str
    affected_radius_km: float


@dataclass
class NotificationData:
    """Notification data structure"""
    title: str
    body: str
    priority: str
    target_users: List[str]
    event_type: str
    location: str
    predicted_impact: str


class PatternDetector:
    """AI-powered pattern detection using the notification agent's intelligence"""
    
    def __init__(self, ai_agent=None):
        self.historical_data = defaultdict(list)
        self.ai_agent = ai_agent  # Reference to the AI agent for intelligent analysis
        self.learning_memory = defaultdict(list)  # Store learning from previous decisions
        
    async def detect_event_cluster(self, events: List[Dict], time_window_minutes: int = 20) -> Optional[EventCluster]:
        """Use AI agent to intelligently detect concerning event clusters"""
        if not events:
            return None
        
        # If AI agent is available, use its intelligence for analysis
        if self.ai_agent:
            return await self._ai_powered_cluster_detection(events, time_window_minutes)
        else:
            # Fallback to basic analysis
            return await self._basic_cluster_detection(events, time_window_minutes)
    
    async def _ai_powered_cluster_detection(self, events: List[Dict], time_window_minutes: int) -> Optional[EventCluster]:
        """Let the AI agent analyze events and determine if they form concerning clusters"""
        
        # Prepare context for AI analysis
        events_summary = self._prepare_events_for_ai_analysis(events, time_window_minutes)
        
        # Enhanced AI prompt for intelligent cluster analysis
        ai_analysis_prompt = f"""
        You are an intelligent city monitoring AI agent. Analyze the following incident data to determine if there are concerning patterns or clusters that require citizen notification.

        INCIDENT DATA:
        {events_summary}

        TIME WINDOW: {time_window_minutes} minutes

        Use your AI reasoning to analyze:
        1. Are there concerning clusters of similar incidents in the same location?
        2. What is the severity level (LOW, MEDIUM, HIGH, CRITICAL) based on:
           - Number of incidents and their frequency
           - Type of incidents (emergency/flooding are more critical than maintenance)
           - Location concentration and population impact
           - Potential cascading effects on citizens
           - Context from incident descriptions
        3. What radius should be affected for notifications (2-15km)?
        4. Should this trigger a notification to citizens?

        Consider factors like:
        - Public safety implications
        - Information utility vs notification fatigue
        - Urgency and time sensitivity
        - Geographic impact scope
        - Citizen preparedness needs

        Respond with a JSON analysis including:
        {{
            "is_cluster": boolean,
            "event_type": "string (if cluster found)",
            "location": "string (if cluster found)", 
            "count": number,
            "severity": "LOW/MEDIUM/HIGH/CRITICAL",
            "affected_radius_km": number,
            "reasoning": "detailed explanation of your analysis",
            "notification_recommended": boolean,
            "confidence": number (0.0-1.0),
            "contributing_factors": ["list of factors"],
            "recommended_actions": ["list of citizen actions"]
        }}
        """
        
        try:
            # Use real AI agent for analysis
            if self.ai_agent:
                ai_response = await self._call_ai_agent_for_analysis(ai_analysis_prompt)
                
                if ai_response.get("is_cluster", False) and ai_response.get("notification_recommended", False):
                    # Store learning for future improvements
                    self._store_ai_decision(events, ai_response)
                    
                    return EventCluster(
                        event_type=ai_response.get("event_type", "Unknown"),
                        location=ai_response.get("location", "Unknown"),
                        count=ai_response.get("count", len(events)),
                        severity=ai_response.get("severity", "MEDIUM"),
                        time_window=f"{time_window_minutes} minutes",
                        affected_radius_km=ai_response.get("affected_radius_km", 5.0)
                    )
                
                return None
            else:
                # Fallback to enhanced simulation with better reasoning
                return await self._enhanced_simulation_analysis(events, time_window_minutes)
            
        except Exception as e:
            print(f"AI cluster analysis failed, using fallback: {e}")
            return await self._basic_cluster_detection(events, time_window_minutes)
    
    
    async def _call_ai_agent_for_analysis(self, prompt: str) -> Dict[str, Any]:
        """Call the real AI agent for intelligent analysis"""
        try:
            # Use the AI agent's generate_content method for real reasoning
            response = await self.ai_agent.generate_content(prompt)
            
            # Parse the JSON response from AI
            if hasattr(response, 'text'):
                response_text = response.text
            else:
                response_text = str(response)
            
            # Extract JSON from response
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                # If no JSON found, create structured response from text
                return self._parse_ai_text_response(response_text)
                
        except Exception as e:
            print(f"Error calling AI agent: {e}")
            # Fall back to enhanced simulation
            return await self._enhanced_simulation_analysis_response()
    
    def _parse_ai_text_response(self, response_text: str) -> Dict[str, Any]:
        """Parse AI text response into structured format"""
        # Basic text parsing for AI responses that don't return JSON
        is_cluster = any(word in response_text.lower() for word in ['cluster', 'pattern', 'multiple', 'concerning'])
        notification_recommended = any(word in response_text.lower() for word in ['notify', 'alert', 'warn', 'inform'])
        
        severity = "MEDIUM"
        if any(word in response_text.lower() for word in ['critical', 'urgent', 'emergency']):
            severity = "CRITICAL"
        elif any(word in response_text.lower() for word in ['high', 'severe', 'serious']):
            severity = "HIGH"
        elif any(word in response_text.lower() for word in ['low', 'minor']):
            severity = "LOW"
        
        return {
            "is_cluster": is_cluster,
            "notification_recommended": notification_recommended,
            "severity": severity,
            "reasoning": response_text[:200] + "..." if len(response_text) > 200 else response_text,
            "confidence": 0.7,
            "event_type": "Infrastructure",  # Default
            "location": "Unknown",
            "count": 1,
            "affected_radius_km": 5.0
        }
    
    async def _enhanced_simulation_analysis(self, events: List[Dict], time_window_minutes: int) -> Optional[EventCluster]:
        """Enhanced simulation with better AI-like reasoning"""
        return await self._simulate_ai_cluster_analysis(events, time_window_minutes)
    
    async def _enhanced_simulation_analysis_response(self) -> Dict[str, Any]:
        """Enhanced simulation response when AI agent fails"""
        return {
            "is_cluster": False,
            "notification_recommended": False,
            "reasoning": "AI analysis unavailable, using fallback logic",
            "confidence": 0.5
        }
    
    def _store_ai_decision(self, events: List[Dict], ai_response: Dict[str, Any]):
        """Store AI decisions for learning and improvement"""
        decision_record = {
            "timestamp": datetime.datetime.now().isoformat(),
            "events_count": len(events),
            "ai_decision": ai_response,
            "events_summary": [{"type": e.get("incidentType"), "location": e.get("location")} for e in events[:3]]
        }
        
        location = ai_response.get("location", "unknown")
        self.learning_memory[f"ai_decisions_{location}"].append(decision_record)
        
        # Keep only last 50 decisions per location
        if len(self.learning_memory[f"ai_decisions_{location}"]) > 50:
            self.learning_memory[f"ai_decisions_{location}"] = self.learning_memory[f"ai_decisions_{location}"][-50:]
    
    async def _simulate_ai_cluster_analysis(self, events: List[Dict], time_window_minutes: int) -> Dict[str, Any]:
        """Simulate AI analysis - in real implementation, this would call the AI agent"""
        
        # Group events by location and type for intelligent analysis
        location_events = defaultdict(list)
        for event in events:
            location_events[event.get('location', 'unknown')].append(event)
        
        # AI-like reasoning for cluster detection
        for location, loc_events in location_events.items():
            event_types = Counter([e.get('incidentType', 'unknown') for e in loc_events])
            
            for event_type, count in event_types.items():
                # AI reasoning: Consider context, not just count
                if self._ai_should_create_cluster(event_type, count, location, loc_events):
                    severity = await self._ai_determine_severity(event_type, count, location, loc_events)
                    radius = await self._ai_calculate_radius(event_type, count, location, severity)
                    
                    return {
                        "is_cluster": True,
                        "event_type": event_type,
                        "location": location,
                        "count": count,
                        "severity": severity,
                        "affected_radius_km": radius,
                        "reasoning": f"AI detected {count} {event_type.lower()} incidents in {location} within {time_window_minutes} minutes. Pattern analysis suggests {severity.lower()} priority notification needed.",
                        "notification_recommended": True
                    }
        
        return {
            "is_cluster": False,
            "notification_recommended": False,
            "reasoning": "AI analysis found no concerning patterns requiring citizen notification."
        }
    
    def _ai_should_create_cluster(self, event_type: str, count: int, location: str, events: List[Dict]) -> bool:
        """AI-like reasoning for whether events constitute a concerning cluster"""
        
        # AI considers multiple factors, not just count
        factors = {
            "event_criticality": self._assess_event_criticality(event_type),
            "frequency_concern": count >= 2,  # AI is more sensitive than fixed threshold
            "location_vulnerability": self._assess_location_vulnerability(location),
            "incident_descriptions": self._analyze_incident_descriptions(events)
        }
        
        # AI reasoning: If incident is critical OR multiple factors indicate concern
        if factors["event_criticality"] == "high":
            return count >= 2  # AI: Even 2 critical events are concerning
        elif factors["event_criticality"] == "medium":
            return count >= 3 and factors["location_vulnerability"] == "high"
        else:
            return count >= 4 and factors["frequency_concern"]
    
    async def _ai_should_create_cluster_enhanced(self, event_type: str, count: int, location: str, events: List[Dict]) -> bool:
        """Enhanced AI-like reasoning using real AI capabilities when available"""
        
        if self.ai_agent:
            # Use real AI agent for decision making
            decision_prompt = f"""
            You are an AI agent analyzing whether {count} {event_type} incidents in {location} constitute a concerning cluster requiring citizen notification.
            
            Event Details:
            {[e.get('description', 'No description')[:100] for e in events[:3]]}
            
            Consider:
            - Public safety impact
            - Frequency and timing
            - Location population density
            - Event severity and type
            
            Respond with: YES (create cluster) or NO (not concerning enough)
            Brief reasoning in one sentence.
            """
            
            try:
                response = await self._call_ai_agent_for_analysis(decision_prompt)
                decision_text = response.get("reasoning", "").lower()
                return "yes" in decision_text or response.get("notification_recommended", False)
            except:
                pass
        
        # Fallback to original logic
        return self._ai_should_create_cluster(event_type, count, location, events)
    
    async def _get_contributing_factors(self, event_type: str, count: int, location: str, events: List[Dict]) -> List[str]:
        """Get contributing factors for AI decision"""
        factors = []
        
        if count >= 3:
            factors.append(f"High frequency: {count} incidents")
        
        if event_type.lower() in ['emergency', 'flooding', 'infrastructure']:
            factors.append(f"Critical event type: {event_type}")
            
        if location in ['HSR Layout', 'Whitefield', 'Electronic City']:
            factors.append(f"High-impact location: {location}")
            
        # Analyze descriptions for severity indicators
        severity_words = ['urgent', 'severe', 'critical', 'complete', 'widespread']
        for event in events:
            description = event.get('description', '').lower()
            if any(word in description for word in severity_words):
                factors.append("Severe incident descriptions detected")
                break
                
        return factors
    
    def _get_recommended_actions(self, event_type: str, severity: str) -> List[str]:
        """Get recommended actions for citizens"""
        actions = []
        
        if severity in ["HIGH", "CRITICAL"]:
            actions.append("Avoid the affected area")
            actions.append("Follow official guidance")
            
        if event_type.lower() == "infrastructure":
            actions.append("Use alternative routes")
            actions.append("Check for service updates")
        elif event_type.lower() == "flooding":
            actions.append("Avoid waterlogged areas")
            actions.append("Stay indoors if possible")
        elif event_type.lower() == "emergency":
            actions.append("Stay safe and alert")
            actions.append("Contact emergency services if needed")
        else:
            actions.append("Stay informed")
            actions.append("Exercise caution")
            
        return actions
    
    async def _ai_determine_severity(self, event_type: str, count: int, location: str, events: List[Dict]) -> str:
        """AI determines severity based on multiple contextual factors"""
        
        severity_score = 0
        
        # Factor 1: Event type criticality
        if event_type.lower() in ['emergency', 'flooding']:
            severity_score += 3
        elif event_type.lower() in ['infrastructure']:
            severity_score += 2
        else:
            severity_score += 1
        
        # Factor 2: Frequency intensity (AI adapts based on type)
        if event_type.lower() in ['emergency', 'flooding']:
            if count >= 4: severity_score += 3
            elif count >= 2: severity_score += 2
            else: severity_score += 1
        else:
            if count >= 6: severity_score += 3
            elif count >= 4: severity_score += 2
            elif count >= 2: severity_score += 1
        
        # Factor 3: Location impact (AI considers population density)
        high_impact_areas = ['HSR Layout', 'Whitefield', 'Koramangala', 'Indiranagar']
        if location in high_impact_areas:
            severity_score += 1
        
        # Factor 4: Incident descriptions (AI analyzes content)
        description_severity = self._analyze_incident_severity_from_descriptions(events)
        severity_score += description_severity
        
        # AI mapping to severity levels
        if severity_score >= 8:
            return "CRITICAL"
        elif severity_score >= 6:
            return "HIGH"
        elif severity_score >= 4:
            return "MEDIUM"
        else:
            return "LOW"
    
    async def _ai_calculate_radius(self, event_type: str, count: int, location: str, severity: str) -> float:
        """AI calculates affected radius based on incident context"""
        
        # Base radius from AI knowledge
        base_radius = {
            'flooding': 6.0,      # AI: Flooding spreads, larger base
            'infrastructure': 4.0, # AI: Power/water affects neighborhoods
            'emergency': 8.0,     # AI: Emergency requires wider alert
            'maintenance': 3.0    # AI: Maintenance is localized
        }
        
        radius = base_radius.get(event_type.lower(), 4.0)
        
        # AI scaling factors
        if severity == "CRITICAL":
            radius *= 1.5
        elif severity == "HIGH":
            radius *= 1.3
        elif severity == "MEDIUM":
            radius *= 1.1
        
        # AI considers count impact
        radius += (count - 1) * 0.5
        
        # AI considers location density
        high_density_areas = ['HSR Layout', 'Koramangala', 'BTM Layout']
        if location in high_density_areas:
            radius *= 1.2
        
        return min(radius, 15.0)  # AI caps at 15km
    
    async def _basic_cluster_detection(self, events: List[Dict], time_window_minutes: int) -> Optional[EventCluster]:
        """Fallback basic cluster detection when AI is not available"""
        location_events = defaultdict(list)
        for event in events:
            location_events[event.get('location', 'unknown')].append(event)
        
        for location, loc_events in location_events.items():
            event_types = Counter([e.get('incidentType', 'unknown') for e in loc_events])
            
            for event_type, count in event_types.items():
                if count >= 3:
                    severity = self._calculate_severity_basic(count, event_type)
                    return EventCluster(
                        event_type=event_type,
                        location=location,
                        count=count,
                        severity=severity,
                        time_window=f"{time_window_minutes} minutes",
                        affected_radius_km=self._calculate_affected_radius_basic(event_type, count)
                    )
        
        return None
    
    def _prepare_events_for_ai_analysis(self, events: List[Dict], time_window_minutes: int) -> str:
        """Prepare events data in a format suitable for AI analysis"""
        summary = f"TIME WINDOW: {time_window_minutes} minutes\n"
        summary += f"TOTAL INCIDENTS: {len(events)}\n\n"
        
        # Group by location for better AI understanding
        location_groups = defaultdict(list)
        for event in events:
            location_groups[event.get('location', 'Unknown')].append(event)
        
        for location, loc_events in location_groups.items():
            summary += f"LOCATION: {location}\n"
            event_types = Counter([e.get('incidentType', 'Unknown') for e in loc_events])
            
            for event_type, count in event_types.items():
                summary += f"  - {event_type}: {count} incidents\n"
                
                # Include sample descriptions for AI context
                sample_events = [e for e in loc_events if e.get('incidentType') == event_type][:2]
                for sample in sample_events:
                    if sample.get('description'):
                        summary += f"    * {sample['description'][:100]}...\n"
            summary += "\n"
        
        return summary
    
    def _assess_event_criticality(self, event_type: str) -> str:
        """AI assessment of event type criticality"""
        critical_events = ['emergency', 'flooding', 'fire', 'gas leak']
        medium_events = ['infrastructure', 'power outage', 'water outage']
        
        if event_type.lower() in critical_events:
            return "high"
        elif event_type.lower() in medium_events:
            return "medium"
        else:
            return "low"
    
    def _assess_location_vulnerability(self, location: str) -> str:
        """AI assessment of location vulnerability"""
        high_vulnerability = ['HSR Layout', 'Whitefield', 'Electronic City', 'Marathahalli']
        
        if location in high_vulnerability:
            return "high"
        else:
            return "medium"
    
    def _analyze_incident_descriptions(self, events: List[Dict]) -> bool:
        """AI analysis of incident descriptions for severity indicators"""
        severity_keywords = ['urgent', 'severe', 'critical', 'major', 'widespread', 'multiple', 'complete']
        
        for event in events:
            description = event.get('description', '').lower()
            if any(keyword in description for keyword in severity_keywords):
                return True
        
        return False
    
    def _analyze_incident_severity_from_descriptions(self, events: List[Dict]) -> int:
        """AI extracts severity score from incident descriptions"""
        severity_score = 0
        high_severity_words = ['urgent', 'critical', 'severe', 'major', 'widespread', 'complete']
        medium_severity_words = ['multiple', 'ongoing', 'affecting', 'reported']
        
        for event in events:
            description = event.get('description', '').lower()
            for word in high_severity_words:
                if word in description:
                    severity_score += 2
                    break
            for word in medium_severity_words:
                if word in description:
                    severity_score += 1
                    break
        
        return min(severity_score, 3)  # Cap at 3
    
    def _calculate_severity_basic(self, count: int, event_type: str) -> str:
        """Basic severity calculation for fallback"""
        if event_type.lower() in ['emergency', 'flooding']:
            if count >= 5:
                return "CRITICAL"
            elif count >= 3:
                return "HIGH"
        elif event_type.lower() in ['infrastructure', 'maintenance']:
            if count >= 8:
                return "HIGH"
            elif count >= 5:
                return "MEDIUM"
        
        return "LOW"
    
    def _calculate_affected_radius_basic(self, event_type: str, count: int) -> float:
        """Basic radius calculation for fallback"""
        base_radius = {
            'flooding': 5.0,
            'infrastructure': 3.0,
            'emergency': 7.0,
            'maintenance': 2.0
        }
        
        radius = base_radius.get(event_type.lower(), 3.0)
        return min(radius * (1 + count * 0.2), 15.0)
    
    async def ai_powered_anomaly_detection(self, current_data: Dict[str, Any], historical_data: List[Dict]) -> Dict[str, Any]:
        """Use AI agent to detect anomalies in data patterns with real intelligence"""
        
        if self.ai_agent and len(historical_data) >= 5:
            # Prepare data for AI analysis
            data_summary = self._prepare_anomaly_data_for_ai(current_data, historical_data)
            
            # Enhanced AI prompt for intelligent anomaly detection
            ai_anomaly_prompt = f"""
            You are an AI agent specializing in anomaly detection for smart city systems. Analyze the following data pattern to detect anomalies.

            CURRENT DATA POINT:
            {json.dumps(current_data, indent=2)}
            
            HISTORICAL CONTEXT (last {len(historical_data)} data points):
            {data_summary}
            
            Use your AI reasoning to determine:
            1. Is the current data point anomalous compared to historical patterns?
            2. What is the confidence level (0.0 to 1.0) of this assessment?
            3. What type of anomaly is it (spike, drop, pattern_break, seasonal_anomaly, system_failure)?
            4. Should this trigger an alert to city operators or citizens?
            5. What is the severity (LOW, MEDIUM, HIGH, CRITICAL)?
            6. What might be the root cause or contributing factors?
            
            Consider contextual factors:
            - Statistical deviation from normal range
            - Time-based patterns (day/night, weekday/weekend, seasonal)
            - System interdependencies and cascading effects
            - Citizen impact and safety implications
            - Historical correlation patterns
            
            Respond with JSON analysis:
            {{
                "is_anomaly": boolean,
                "confidence": number,
                "anomaly_type": "string",
                "severity": "LOW/MEDIUM/HIGH/CRITICAL",
                "should_alert": boolean,
                "reasoning": "detailed explanation",
                "root_causes": ["possible causes"],
                "citizen_impact": "impact description",
                "recommended_actions": ["actions to take"]
            }}
            """
            
            try:
                # Use real AI agent for anomaly analysis
                ai_response = await self._call_ai_agent_for_analysis(ai_anomaly_prompt)
                
                # Enhance response with additional metrics
                ai_response["z_score"] = self._calculate_z_score(current_data, historical_data)
                ai_response["trend_direction"] = self._calculate_trend_direction(historical_data, current_data)
                
                # Store learning from AI decision
                self._store_anomaly_decision(current_data, historical_data, ai_response)
                
                return ai_response
                
            except Exception as e:
                print(f"AI anomaly detection failed: {e}")
                # Fall back to enhanced statistical detection
                return await self._enhanced_statistical_anomaly_detection(current_data, historical_data)
        
        # Fallback to basic statistical detection
        return self._basic_anomaly_detection(current_data, historical_data)
    
    
    async def _enhanced_statistical_anomaly_detection(self, current_data: Dict[str, Any], historical_data: List[Dict]) -> Dict[str, Any]:
        """Enhanced statistical anomaly detection when AI is unavailable"""
        
        current_value = self._extract_numeric_value(current_data)
        historical_values = [self._extract_numeric_value(d) for d in historical_data if self._extract_numeric_value(d) is not None]
        
        if len(historical_values) < 3:
            return {"is_anomaly": False, "confidence": 0.0, "reasoning": "Insufficient historical data"}
        
        # Enhanced statistical analysis
        mean_val = np.mean(historical_values)
        std_val = np.std(historical_values)
        median_val = np.median(historical_values)
        
        if std_val == 0:
            is_anomaly = current_value != mean_val
            confidence = 1.0 if is_anomaly else 0.0
            z_score = float('inf') if is_anomaly else 0.0
        else:
            z_score = abs((current_value - mean_val) / std_val)
            
            # Multi-factor anomaly detection
            is_anomaly = self._multi_factor_anomaly_decision(current_value, historical_values, current_data)
            confidence = min(0.95, z_score / 3.0)
        
        anomaly_type = self._determine_anomaly_type(current_value, historical_values)
        severity = self._determine_anomaly_severity(z_score, anomaly_type)
        
        return {
            "is_anomaly": is_anomaly,
            "confidence": confidence,
            "anomaly_type": anomaly_type,
            "severity": severity,
            "z_score": z_score,
            "should_alert": is_anomaly and confidence > 0.7,
            "reasoning": f"Enhanced statistical analysis: {'anomalous' if is_anomaly else 'normal'} pattern (z-score: {z_score:.2f})",
            "root_causes": self._infer_statistical_causes(z_score, anomaly_type),
            "citizen_impact": self._assess_citizen_impact(anomaly_type, severity),
            "recommended_actions": self._get_statistical_recommendations(severity, anomaly_type)
        }
    
    def _calculate_z_score(self, current_data: Dict[str, Any], historical_data: List[Dict]) -> float:
        """Calculate z-score for current data point"""
        current_value = self._extract_numeric_value(current_data)
        historical_values = [self._extract_numeric_value(d) for d in historical_data if self._extract_numeric_value(d) is not None]
        
        if len(historical_values) < 2:
            return 0.0
            
        mean_val = np.mean(historical_values)
        std_val = np.std(historical_values)
        
        if std_val == 0:
            return 0.0
            
        return abs((current_value - mean_val) / std_val)
    
    def _calculate_trend_direction(self, historical_data: List[Dict], current_data: Dict[str, Any]) -> str:
        """Calculate trend direction"""
        historical_values = [self._extract_numeric_value(d) for d in historical_data if self._extract_numeric_value(d) is not None]
        current_value = self._extract_numeric_value(current_data)
        
        if len(historical_values) < 3:
            return "unknown"
            
        recent_avg = np.mean(historical_values[-3:])
        
        if current_value > recent_avg * 1.1:
            return "increasing"
        elif current_value < recent_avg * 0.9:
            return "decreasing"
        else:
            return "stable"
    
    def _store_anomaly_decision(self, current_data: Dict[str, Any], historical_data: List[Dict], ai_response: Dict[str, Any]):
        """Store anomaly detection decisions for learning"""
        decision_record = {
            "timestamp": datetime.datetime.now().isoformat(),
            "current_value": self._extract_numeric_value(current_data),
            "historical_count": len(historical_data),
            "ai_decision": ai_response,
            "data_type": current_data.get("type", "unknown")
        }
        
        data_type = current_data.get("type", "general")
        self.learning_memory[f"anomaly_decisions_{data_type}"].append(decision_record)
        
        # Keep only last 30 decisions per data type
        if len(self.learning_memory[f"anomaly_decisions_{data_type}"]) > 30:
            self.learning_memory[f"anomaly_decisions_{data_type}"] = self.learning_memory[f"anomaly_decisions_{data_type}"][-30:]
    
    def _multi_factor_anomaly_decision(self, current_value: float, historical_values: List[float], context: Dict[str, Any]) -> bool:
        """Enhanced multi-factor anomaly decision"""
        
        mean_val = np.mean(historical_values)
        std_val = np.std(historical_values)
        
        if std_val == 0:
            return current_value != mean_val
        
        z_score = abs((current_value - mean_val) / std_val)
        
        # Base threshold
        threshold = 2.0
        
        # Adjust threshold based on context
        data_type = context.get('type', 'unknown')
        location = context.get('location', 'unknown')
        
        # More sensitive for critical systems
        if data_type in ['emergency', 'critical_infrastructure', 'safety']:
            threshold = 1.5
        elif data_type in ['environmental', 'traffic']:
            threshold = 2.0
        else:
            threshold = 2.5
        
        # Consider data variance patterns
        recent_variance = np.std(historical_values[-5:]) if len(historical_values) >= 5 else std_val
        if recent_variance > std_val * 1.5:  # High recent variance
            threshold += 0.5
        
        return z_score > threshold
    
    def _infer_statistical_causes(self, z_score: float, anomaly_type: str) -> List[str]:
        """Infer possible causes based on statistical patterns"""
        causes = []
        
        if z_score > 4.0:
            causes.append("Extreme statistical deviation - possible system failure")
        elif z_score > 3.0:
            causes.append("Significant pattern break - investigate system changes")
        elif z_score > 2.0:
            causes.append("Notable deviation - monitor for developing issues")
        
        if anomaly_type == "spike":
            causes.append("Sudden increase - check for load spikes or incidents")
        elif anomaly_type == "drop":
            causes.append("Sudden decrease - verify system functionality")
        elif anomaly_type == "pattern_break":
            causes.append("Pattern disruption - review recent system changes")
        
        return causes if causes else ["Statistical anomaly detected"]
    
    def _assess_citizen_impact(self, anomaly_type: str, severity: str) -> str:
        """Assess potential impact on citizens"""
        
        if severity == "CRITICAL":
            return "High citizen impact - immediate attention required"
        elif severity == "HIGH":
            return "Moderate citizen impact - prompt response needed"
        elif severity == "MEDIUM":
            return "Potential citizen impact - monitoring recommended"
        else:
            return "Low citizen impact - routine monitoring"
    
    def _get_statistical_recommendations(self, severity: str, anomaly_type: str) -> List[str]:
        """Get recommendations based on statistical analysis"""
        recommendations = []
        
        if severity in ["CRITICAL", "HIGH"]:
            recommendations.append("Investigate immediately")
            recommendations.append("Consider citizen notification")
            recommendations.append("Check system dependencies")
        
        if anomaly_type in ["spike", "drop"]:
            recommendations.append("Verify data source integrity")
            recommendations.append("Check for external factors")
        
        recommendations.append("Continue monitoring pattern")
        
        return recommendations
        """Simulate AI-powered anomaly detection"""
        
        # Extract numeric values for analysis
        current_value = self._extract_numeric_value(current_data)
        historical_values = [self._extract_numeric_value(d) for d in historical_data if self._extract_numeric_value(d) is not None]
        
        if len(historical_values) < 3:
            return {"is_anomaly": False, "confidence": 0.0, "reasoning": "Insufficient historical data for AI analysis"}
        
        # AI-like analysis considering context
        mean_val = np.mean(historical_values)
        std_val = np.std(historical_values)
        
        if std_val == 0:
            is_anomaly = current_value != mean_val
            confidence = 1.0 if is_anomaly else 0.0
        else:
            z_score = abs((current_value - mean_val) / std_val)
            
            # AI considers multiple factors, not just z-score
            is_anomaly = self._ai_anomaly_decision(current_value, historical_values, current_data)
            confidence = min(0.95, z_score / 3.0)  # Scale z-score to confidence
        
        anomaly_type = self._determine_anomaly_type(current_value, historical_values)
        severity = self._determine_anomaly_severity(z_score if std_val > 0 else 0, anomaly_type)
        
        return {
            "is_anomaly": is_anomaly,
            "confidence": confidence,
            "anomaly_type": anomaly_type,
            "severity": severity,
            "z_score": z_score if std_val > 0 else 0,
            "should_alert": is_anomaly and confidence > 0.7,
            "reasoning": f"AI detected {'anomalous' if is_anomaly else 'normal'} pattern with {confidence:.1%} confidence. Z-score: {z_score:.2f}"
        }
    
    def _ai_anomaly_decision(self, current_value: float, historical_values: List[float], context: Dict[str, Any]) -> bool:
        """AI decision making for anomaly detection considering context"""
        
        mean_val = np.mean(historical_values)
        std_val = np.std(historical_values)
        
        if std_val == 0:
            return current_value != mean_val
        
        z_score = abs((current_value - mean_val) / std_val)
        
        # AI considers adaptive thresholds based on context
        data_type = context.get('type', 'unknown')
        location = context.get('location', 'unknown')
        
        # Different thresholds for different data types (AI learning)
        if data_type in ['emergency', 'critical_infrastructure']:
            threshold = 1.5  # AI: More sensitive for critical data
        elif data_type in ['environmental', 'traffic']:
            threshold = 2.0  # AI: Standard sensitivity
        else:
            threshold = 2.5  # AI: Less sensitive for routine data
        
        # AI considers location-specific patterns
        high_variance_locations = ['Downtown', 'Electronic City']
        if location in high_variance_locations:
            threshold += 0.5  # AI: Less sensitive in high-variance areas
        
        return z_score > threshold
    
    def _determine_anomaly_type(self, current_value: float, historical_values: List[float]) -> str:
        """AI determines the type of anomaly detected"""
        mean_val = np.mean(historical_values)
        max_val = max(historical_values)
        min_val = min(historical_values)
        
        if current_value > max_val * 1.2:
            return "spike"
        elif current_value < min_val * 0.8:
            return "drop"
        elif current_value > mean_val * 1.5:
            return "high_deviation"
        elif current_value < mean_val * 0.5:
            return "low_deviation"
        else:
            return "pattern_break"
    
    def _determine_anomaly_severity(self, z_score: float, anomaly_type: str) -> str:
        """AI determines severity of detected anomaly"""
        base_severity = "LOW"
        
        if z_score > 4.0:
            base_severity = "CRITICAL"
        elif z_score > 3.0:
            base_severity = "HIGH"
        elif z_score > 2.0:
            base_severity = "MEDIUM"
        
        # AI adjusts severity based on anomaly type
        if anomaly_type in ["spike", "drop"]:
            if base_severity == "MEDIUM":
                base_severity = "HIGH"
            elif base_severity == "LOW":
                base_severity = "MEDIUM"
        
        return base_severity
    
    def detect_anomaly(self, current_value: float, historical_values: List[float]) -> bool:
        """Basic anomaly detection - kept for backward compatibility"""
        return self._basic_anomaly_detection({"value": current_value}, [{"value": v} for v in historical_values])["is_anomaly"]
    
    def _basic_anomaly_detection(self, current_data: Dict[str, Any], historical_data: List[Dict]) -> Dict[str, Any]:
        """Basic statistical anomaly detection"""
        current_value = self._extract_numeric_value(current_data)
        historical_values = [self._extract_numeric_value(d) for d in historical_data if self._extract_numeric_value(d) is not None]
        
        if len(historical_values) < 5:
            return {"is_anomaly": False, "confidence": 0.0, "reasoning": "Insufficient data"}
            
        mean = np.mean(historical_values)
        std = np.std(historical_values)
        
        if std == 0:
            is_anomaly = current_value != mean
            confidence = 1.0 if is_anomaly else 0.0
        else:
            z_score = abs((current_value - mean) / std)
            is_anomaly = z_score > 2.0  # Standard threshold
            confidence = min(0.95, z_score / 3.0)
        
        return {
            "is_anomaly": is_anomaly,
            "confidence": confidence,
            "reasoning": f"Basic statistical analysis: {'anomaly' if is_anomaly else 'normal'}"
        }
    
    def _extract_numeric_value(self, data: Dict[str, Any]) -> Optional[float]:
        """Extract numeric value from data dict for analysis"""
        if 'value' in data:
            return float(data['value'])
        elif 'count' in data:
            return float(data['count'])
        elif 'level' in data:
            return float(data['level'])
        elif 'index' in data:
            return float(data['index'])
        
        # Try to find first numeric value
        for key, value in data.items():
            try:
                return float(value)
            except (ValueError, TypeError):
                continue
        
        return None
    
    def _prepare_anomaly_data_for_ai(self, current_data: Dict[str, Any], historical_data: List[Dict]) -> str:
        """Prepare anomaly data for AI analysis"""
        summary = "HISTORICAL PATTERN ANALYSIS:\n"
        
        # Extract values for trend analysis
        values = [self._extract_numeric_value(d) for d in historical_data if self._extract_numeric_value(d) is not None]
        
        if values:
            summary += f"Historical Range: {min(values):.2f} - {max(values):.2f}\n"
            summary += f"Historical Average: {np.mean(values):.2f}\n"
            summary += f"Standard Deviation: {np.std(values):.2f}\n"
            summary += f"Recent Trend: {values[-3:] if len(values) >= 3 else values}\n"
        
        summary += f"\nRecent Data Points (last {min(5, len(historical_data))}):\n"
        for i, data_point in enumerate(historical_data[-5:]):
            summary += f"  {i+1}. {data_point}\n"
        
        return summary
    
    async def predict_future_risk(self, location: str, event_type: str) -> Dict[str, Any]:
        """AI-powered risk prediction based on patterns and context with real intelligence"""
        
        if self.ai_agent:
            return await self._ai_powered_risk_prediction(location, event_type)
        else:
            return await self._enhanced_risk_prediction(location, event_type)
    
    async def _ai_powered_risk_prediction(self, location: str, event_type: str) -> Dict[str, Any]:
        """Use real AI agent to predict future risks with advanced contextual analysis"""
        
        historical = self.historical_data.get(f"{location}_{event_type}", [])
        
        # Prepare comprehensive context for AI analysis
        risk_context = self._prepare_comprehensive_risk_context(location, event_type, historical)
        
        # Enhanced AI prompt for intelligent risk prediction
        ai_risk_prompt = f"""
        You are an AI agent specializing in predictive analytics for smart city risk management. Analyze the comprehensive data to predict future incident risks.

        LOCATION: {location}
        INCIDENT TYPE: {event_type}
        
        COMPREHENSIVE RISK CONTEXT:
        {risk_context}
        
        HISTORICAL LEARNING:
        {self._get_historical_learning_context(location, event_type)}
        
        Use your AI intelligence to predict:
        1. Risk level (LOW, MEDIUM, HIGH, CRITICAL) for next incident
        2. Confidence level (0.0 to 1.0) in your prediction
        3. Predicted timeframe for next incident occurrence
        4. Primary contributing factors driving the risk
        5. Recommended preventive actions for city operators
        6. Citizen preparedness recommendations
        
        Consider advanced factors:
        - Multi-dimensional pattern analysis (temporal, spatial, contextual)
        - System interdependencies and cascading effects
        - Seasonal and environmental correlations
        - Socioeconomic and infrastructure vulnerability
        - Historical effectiveness of interventions
        - Real-time situational context
        
        Respond with comprehensive JSON analysis:
        {{
            "risk_level": "LOW/MEDIUM/HIGH/CRITICAL",
            "confidence": number,
            "predicted_timeframe": "descriptive timeframe",
            "probability_percentage": number,
            "contributing_factors": ["detailed factors"],
            "risk_drivers": ["primary risk drivers"],
            "preventive_actions": ["operator actions"],
            "citizen_recommendations": ["citizen actions"],
            "monitoring_priorities": ["what to monitor"],
            "escalation_triggers": ["when to escalate"],
            "reasoning": "detailed AI analysis",
            "uncertainty_factors": ["sources of uncertainty"]
        }}
        """
        
        try:
            # Use real AI agent for risk prediction
            ai_response = await self._call_ai_agent_for_analysis(ai_risk_prompt)
            
            # Enhance AI response with additional analytics
            ai_response["historical_frequency"] = len(historical) / 30.0 if historical else 0.0  # per month
            ai_response["trend_analysis"] = self._analyze_risk_trends(historical)
            ai_response["location_risk_profile"] = self._get_location_risk_profile(location)
            
            # Store learning for continuous improvement
            self._store_risk_prediction(location, event_type, ai_response)
            
            return ai_response
            
        except Exception as e:
            print(f"AI risk prediction failed: {e}")
            # Fall back to enhanced prediction
            return await self._enhanced_risk_prediction(location, event_type)
    
    async def _enhanced_risk_prediction(self, location: str, event_type: str) -> Dict[str, Any]:
        """Enhanced risk prediction when AI agent is unavailable"""
        
        historical = self.historical_data.get(f"{location}_{event_type}", [])
        
        if len(historical) < 3:
            return {
                "risk_level": "UNKNOWN", 
                "confidence": 0.0, 
                "predicted_timeframe": None,
                "reasoning": "Insufficient historical data for enhanced prediction",
                "contributing_factors": ["Limited data availability"],
                "preventive_actions": ["Increase data collection"],
                "citizen_recommendations": ["Stay informed through official channels"]
            }
        
        # Enhanced analytics
        recent_events = [h for h in historical if h > (datetime.datetime.now().timestamp() - 7*24*3600)]
        
        # Multi-factor risk analysis
        risk_factors = self._enhanced_risk_factor_analysis(location, event_type, recent_events, historical)
        
        # AI-like risk calculation with multiple dimensions
        risk_score = self._calculate_enhanced_risk_score(risk_factors)
        
        # Intelligent risk level determination
        risk_level, confidence = self._determine_enhanced_risk_level(risk_score, risk_factors)
        
        # Advanced timing prediction
        predicted_time = self._predict_enhanced_timing(risk_level, recent_events, historical, event_type)
        
        return {
            "risk_level": risk_level,
            "confidence": confidence,
            "predicted_timeframe": predicted_time,
            "probability_percentage": risk_score * 100,
            "risk_score": risk_score,
            "contributing_factors": risk_factors["contributing_factors"],
            "risk_drivers": risk_factors["primary_drivers"],
            "preventive_actions": self._get_enhanced_preventive_actions(risk_level, event_type, location),
            "citizen_recommendations": self._get_enhanced_citizen_recommendations(risk_level, event_type),
            "reasoning": f"Enhanced multi-factor analysis of {len(historical)} historical incidents and {len(recent_events)} recent events in {location}",
            "monitoring_priorities": self._get_monitoring_priorities(event_type, risk_level),
            "escalation_triggers": self._get_escalation_triggers(risk_level, event_type)
        }
    
    async def _ai_powered_risk_prediction(self, location: str, event_type: str) -> Dict[str, Any]:
        """Use AI agent to predict future risks with contextual analysis"""
        
        historical = self.historical_data.get(f"{location}_{event_type}", [])
        
        # Prepare context for AI analysis
        risk_context = self._prepare_risk_context(location, event_type, historical)
        
        ai_prompt = f"""
        Analyze the risk of future incidents based on the following data:
        
        LOCATION: {location}
        INCIDENT TYPE: {event_type}
        
        CONTEXT ANALYSIS:
        {risk_context}
        
        Please predict:
        1. Risk level (LOW, MEDIUM, HIGH, CRITICAL)
        2. Confidence level (0.0 to 1.0)
        3. Predicted timeframe for next incident
        4. Contributing factors
        5. Recommended actions
        
        Consider:
        - Historical frequency patterns
        - Location-specific vulnerabilities
        - Seasonal/temporal patterns
        - Infrastructure dependencies
        - Recent trend analysis
        
        Provide JSON response with risk assessment.
        """
        
        # Simulate AI risk prediction
        return await self._simulate_ai_risk_prediction(location, event_type, historical)
    
    async def _simulate_ai_risk_prediction(self, location: str, event_type: str, historical: List) -> Dict[str, Any]:
        """Simulate AI-powered risk prediction with intelligent analysis"""
        
        if len(historical) < 3:
            return {
                "risk_level": "UNKNOWN", 
                "confidence": 0.0, 
                "predicted_time": None,
                "reasoning": "Insufficient historical data for AI prediction",
                "contributing_factors": ["Limited data availability"],
                "recommended_actions": ["Collect more incident data"]
            }
        
        # AI analyzes recent patterns (last 7 days)
        recent_events = [h for h in historical if h > (datetime.datetime.now().timestamp() - 7*24*3600)]
        
        # AI considers multiple factors for risk calculation
        risk_factors = self._ai_analyze_risk_factors(location, event_type, recent_events, historical)
        
        # AI calculates risk score based on multiple factors
        risk_score = self._ai_calculate_risk_score(risk_factors)
        
        # AI determines risk level with contextual understanding
        risk_level, confidence = self._ai_determine_risk_level(risk_score, risk_factors)
        
        # AI predicts timing based on patterns
        predicted_time = self._ai_predict_timing(risk_level, recent_events, historical)
        
        return {
            "risk_level": risk_level,
            "confidence": confidence,
            "predicted_time": predicted_time,
            "risk_score": risk_score,
            "contributing_factors": risk_factors["contributing_factors"],
            "reasoning": f"AI analysis of {len(historical)} historical incidents and {len(recent_events)} recent events in {location}",
            "recommended_actions": self._ai_recommend_actions(risk_level, event_type, location)
        }
    
    def _ai_analyze_risk_factors(self, location: str, event_type: str, recent_events: List, historical: List) -> Dict[str, Any]:
        """AI analyzes multiple risk factors"""
        
        factors = {
            "frequency_score": len(recent_events) / 7.0,  # Events per day
            "trend_score": self._calculate_trend_score(historical),
            "location_vulnerability": self._assess_location_risk(location),
            "event_criticality": self._assess_event_type_risk(event_type),
            "seasonal_factor": self._assess_seasonal_risk(event_type),
            "contributing_factors": []
        }
        
        # AI identifies contributing factors
        if factors["frequency_score"] > 0.5:
            factors["contributing_factors"].append("High recent incident frequency")
        
        if factors["trend_score"] > 0.7:
            factors["contributing_factors"].append("Increasing incident trend")
        
        if factors["location_vulnerability"] == "high":
            factors["contributing_factors"].append(f"High vulnerability area: {location}")
        
        if factors["event_criticality"] == "high":
            factors["contributing_factors"].append(f"Critical incident type: {event_type}")
        
        return factors
    
    def _ai_calculate_risk_score(self, risk_factors: Dict[str, Any]) -> float:
        """AI calculates composite risk score"""
        
        weights = {
            "frequency_score": 0.3,
            "trend_score": 0.25,
            "location_vulnerability": 0.2,
            "event_criticality": 0.15,
            "seasonal_factor": 0.1
        }
        
        risk_score = 0.0
        
        # Weighted combination of factors
        risk_score += risk_factors["frequency_score"] * weights["frequency_score"]
        risk_score += risk_factors["trend_score"] * weights["trend_score"]
        
        # Convert categorical to numeric
        location_score = 0.8 if risk_factors["location_vulnerability"] == "high" else 0.4
        risk_score += location_score * weights["location_vulnerability"]
        
        criticality_score = 0.9 if risk_factors["event_criticality"] == "high" else 0.5
        risk_score += criticality_score * weights["event_criticality"]
        
        risk_score += risk_factors["seasonal_factor"] * weights["seasonal_factor"]
        
        return min(risk_score, 1.0)
    
    def _ai_determine_risk_level(self, risk_score: float, risk_factors: Dict[str, Any]) -> tuple:
        """AI determines risk level and confidence"""
        
        # AI uses adaptive thresholds based on context
        if risk_factors["event_criticality"] == "high":
            # Lower thresholds for critical events
            if risk_score > 0.4:
                return "HIGH", min(0.9, 0.6 + risk_score * 0.4)
            elif risk_score > 0.25:
                return "MEDIUM", min(0.8, 0.5 + risk_score * 0.3)
        else:
            # Standard thresholds for normal events
            if risk_score > 0.6:
                return "HIGH", min(0.9, 0.6 + risk_score * 0.3)
            elif risk_score > 0.35:
                return "MEDIUM", min(0.8, 0.4 + risk_score * 0.4)
        
        return "LOW", max(0.3, 0.6 - risk_score * 0.2)
    
    def _ai_predict_timing(self, risk_level: str, recent_events: List, historical: List) -> str:
        """AI predicts timing based on patterns"""
        
        if risk_level == "HIGH":
            if len(recent_events) >= 2:
                return "next 2-4 hours"
            else:
                return "next 6-12 hours"
        elif risk_level == "MEDIUM":
            return "next 12-24 hours"
        else:
            return "next 2-7 days"
    
    def _ai_recommend_actions(self, risk_level: str, event_type: str, location: str) -> List[str]:
        """AI recommends actions based on risk assessment"""
        
        actions = []
        
        if risk_level in ["HIGH", "CRITICAL"]:
            actions.append("Deploy preventive measures immediately")
            actions.append("Increase monitoring in affected area")
            actions.append("Prepare emergency response teams")
        
        if event_type.lower() in ["infrastructure", "power"]:
            actions.append("Check power grid stability")
            actions.append("Verify backup systems")
        
        if event_type.lower() in ["flooding", "emergency"]:
            actions.append("Monitor weather conditions")
            actions.append("Prepare evacuation routes")
        
        actions.append(f"Focus attention on {location} area")
        
        return actions
    
    def _basic_risk_prediction(self, location: str, event_type: str) -> Dict[str, Any]:
        """Fallback basic risk prediction"""
        historical = self.historical_data.get(f"{location}_{event_type}", [])
        
        if len(historical) < 3:
            return {"risk_level": "UNKNOWN", "confidence": 0.0, "predicted_time": None}
        
        recent_events = [h for h in historical if h > (datetime.datetime.now().timestamp() - 7*24*3600)]
        risk_score = len(recent_events) / 7.0
        
        if risk_score > 1.0:
            risk_level = "HIGH"
            confidence = min(0.9, 0.6 + risk_score * 0.1)
        elif risk_score > 0.3:
            risk_level = "MEDIUM"
            confidence = min(0.7, 0.4 + risk_score * 0.2)
        else:
            risk_level = "LOW"
            confidence = max(0.3, 0.6 - risk_score * 0.1)
        
        return {
            "risk_level": risk_level,
            "confidence": confidence,
            "predicted_time": "next 3-6 hours" if risk_level == "HIGH" else "next 24-48 hours"
        }
    
    def _prepare_risk_context(self, location: str, event_type: str, historical: List) -> str:
        """Prepare risk context for AI analysis"""
        context = f"RISK ASSESSMENT CONTEXT:\n"
        context += f"Location: {location}\n"
        context += f"Incident Type: {event_type}\n"
        context += f"Historical Incidents: {len(historical)}\n"
        
        if historical:
            recent_count = len([h for h in historical if h > (datetime.datetime.now().timestamp() - 7*24*3600)])
            context += f"Recent Incidents (7 days): {recent_count}\n"
            context += f"Average Frequency: {len(historical)/30:.2f} per month\n"
        
        context += f"Location Risk Profile: {self._assess_location_risk(location)}\n"
        context += f"Event Type Criticality: {self._assess_event_type_risk(event_type)}\n"
        
        return context
    
    def _calculate_trend_score(self, historical: List) -> float:
        """Calculate trend score from historical data"""
        if len(historical) < 6:
            return 0.5
        
        # Compare recent vs older periods
        mid_point = len(historical) // 2
        recent_avg = len(historical[mid_point:]) / (len(historical) - mid_point)
        older_avg = len(historical[:mid_point]) / mid_point
        
        if older_avg == 0:
            return 1.0 if recent_avg > 0 else 0.0
        
        trend_ratio = recent_avg / older_avg
        return min(trend_ratio / 2.0, 1.0)
    
    def _assess_location_risk(self, location: str) -> str:
        """Assess location-specific risk factors"""
        high_risk_locations = ['HSR Layout', 'Electronic City', 'Whitefield', 'Outer Ring Road']
        medium_risk_locations = ['Koramangala', 'Indiranagar', 'BTM Layout']
        
        if location in high_risk_locations:
            return "high"
        elif location in medium_risk_locations:
            return "medium"
        else:
            return "low"
    
    def _assess_event_type_risk(self, event_type: str) -> str:
        """Assess event type criticality"""
        high_risk_events = ['emergency', 'flooding', 'fire', 'infrastructure']
        medium_risk_events = ['maintenance', 'traffic', 'utilities']
        
        if event_type.lower() in high_risk_events:
            return "high"
        elif event_type.lower() in medium_risk_events:
            return "medium"
        else:
            return "low"
    
    def _assess_seasonal_risk(self, event_type: str) -> float:
        """Assess seasonal risk factors"""
        current_month = datetime.datetime.now().month
        
        # Monsoon season risk for flooding
        if event_type.lower() in ['flooding', 'waterlogging'] and current_month in [6, 7, 8, 9]:
            return 0.3
        
        # Summer risk for power issues
        if event_type.lower() in ['infrastructure', 'power'] and current_month in [3, 4, 5]:
            return 0.2
        
        return 0.1
    
    def _prepare_comprehensive_risk_context(self, location: str, event_type: str, historical: List) -> str:
        """Prepare comprehensive context for AI risk analysis"""
        context = f"COMPREHENSIVE RISK ASSESSMENT CONTEXT:\n"
        context += f"Location: {location}\n"
        context += f"Incident Type: {event_type}\n"
        context += f"Historical Incidents: {len(historical)}\n"
        
        if historical:
            recent_count = len([h for h in historical if h > (datetime.datetime.now().timestamp() - 7*24*3600)])
            monthly_avg = len(historical)/30.0 if len(historical) > 0 else 0
            context += f"Recent Incidents (7 days): {recent_count}\n"
            context += f"Monthly Average: {monthly_avg:.2f} incidents\n"
        
        context += f"Location Risk Profile: {self._get_location_risk_profile(location)}\n"
        context += f"Event Type Criticality: {self._assess_event_type_risk(event_type)}\n"
        context += f"Current Season Impact: {self._assess_seasonal_risk(event_type)}\n"
        
        return context
    
    def _get_historical_learning_context(self, location: str, event_type: str) -> str:
        """Get historical learning context from previous AI decisions"""
        learning_key = f"risk_predictions_{location}_{event_type}"
        previous_predictions = self.learning_memory.get(learning_key, [])
        
        if not previous_predictions:
            return "No previous AI learning data available."
        
        context = f"HISTORICAL AI LEARNING CONTEXT:\n"
        context += f"Previous Predictions: {len(previous_predictions)}\n"
        
        return context
    
    def _get_location_risk_profile(self, location: str) -> Dict[str, Any]:
        """Get comprehensive location risk profile"""
        risk_profiles = {
            'HSR Layout': {
                'vulnerability': 'high',
                'population_density': 'high', 
                'risk_factors': ['high density', 'growing area', 'infrastructure strain']
            },
            'Electronic City': {
                'vulnerability': 'high',
                'population_density': 'high',
                'risk_factors': ['IT hub', 'traffic congestion', 'power demand']
            },
            'Whitefield': {
                'vulnerability': 'high',
                'population_density': 'high',
                'risk_factors': ['rapid development', 'infrastructure lag']
            }
        }
        
        return risk_profiles.get(location, {
            'vulnerability': 'medium',
            'population_density': 'medium',
            'risk_factors': ['area assessment needed']
        })
    
    def _analyze_risk_trends(self, historical: List) -> Dict[str, Any]:
        """Analyze risk trends from historical data"""
        if len(historical) < 6:
            return {"trend": "insufficient_data", "direction": "unknown"}
        
        # Simple trend analysis
        sorted_data = sorted(historical)
        mid_point = len(sorted_data) // 2
        
        recent_period = sorted_data[mid_point:]
        older_period = sorted_data[:mid_point]
        
        if len(recent_period) > len(older_period):
            trend = "increasing"
        elif len(recent_period) < len(older_period):
            trend = "decreasing"
        else:
            trend = "stable"
        
        return {"trend": trend}
    
    def _store_risk_prediction(self, location: str, event_type: str, prediction: Dict[str, Any]):
        """Store risk prediction for learning"""
        prediction_record = {
            "timestamp": datetime.datetime.now().isoformat(),
            "location": location,
            "event_type": event_type,
            "predicted_risk": prediction.get("risk_level"),
            "confidence": prediction.get("confidence")
        }
        
        learning_key = f"risk_predictions_{location}_{event_type}"
        self.learning_memory[learning_key].append(prediction_record)
        
        # Keep only last 20 predictions
        if len(self.learning_memory[learning_key]) > 20:
            self.learning_memory[learning_key] = self.learning_memory[learning_key][-20:]


class FirebaseNotificationService:
    """Firebase push notification service"""
    
    def __init__(self, service_account_path: Optional[str] = None):
        self.app = None
        self.initialized = False
        if service_account_path:
            self._initialize_firebase(service_account_path)
    
    def _initialize_firebase(self, service_account_path: str):
        """Initialize Firebase Admin SDK"""
        try:
            if not firebase_admin._apps:
                cred = credentials.Certificate(service_account_path)
                self.app = firebase_admin.initialize_app(cred)
            else:
                self.app = firebase_admin.get_app()
            self.initialized = True
        except Exception as e:
            print(f"Firebase initialization error: {e}")
            self.initialized = False
    
    async def send_notification(self, notification: NotificationData) -> Dict[str, Any]:
        """Send push notification to target users"""
        if not self.initialized:
            # Mock response for development
            return {
                "status": "success",
                "message": f"Mock notification sent to {len(notification.target_users)} users",
                "notification_preview": {
                    "title": notification.title,
                    "body": notification.body,
                    "priority": notification.priority
                }
            }
        
        try:
            # Create FCM message
            message = messaging.MulticastMessage(
                notification=messaging.Notification(
                    title=notification.title,
                    body=notification.body
                ),
                data={
                    "event_type": notification.event_type,
                    "location": notification.location,
                    "predicted_impact": notification.predicted_impact,
                    "priority": notification.priority
                },
                tokens=notification.target_users  # Device tokens
            )
            
            # Send the message
            response = await messaging.send_multicast(message)
            
            return {
                "status": "success",
                "success_count": response.success_count,
                "failure_count": response.failure_count,
                "responses": response.responses
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def analyze_cross_agent_patterns(self, all_data: Dict[str, List]) -> List[Dict[str, Any]]:
        """Analyze patterns across multiple agent data sources"""
        
        patterns = []
        
        # AI-powered cross-agent pattern detection
        if self.ai_agent:
            ai_patterns = await self._ai_cross_agent_pattern_analysis(all_data)
            patterns.extend(ai_patterns)
        
        # Scenario-based patterns
        patterns.extend(await self._analyze_scenario_patterns(all_data))
        
        return patterns
    
    async def _ai_cross_agent_pattern_analysis(self, all_data: Dict[str, List]) -> List[Dict[str, Any]]:
        """Use AI to detect complex cross-agent patterns"""
        
        ai_prompt = f"""
        Analyze data from multiple city monitoring agents to identify complex patterns:
        
        EVENT DATA: {len(all_data.get('events', []))} events
        ENVIRONMENT DATA: {len(all_data.get('environment', []))} readings  
        USER REPORTS: {len(all_data.get('user_reports', []))} reports
        
        DATA SUMMARY:
        {self._prepare_cross_agent_summary(all_data)}
        
        Identify:
        1. Cross-system correlations (e.g., infrastructure events + environment changes)
        2. Cascading failure patterns
        3. Unusual multi-agent anomalies
        4. Predictive patterns across domains
        5. Systemic vulnerabilities
        
        Focus on patterns that require multi-agent intelligence to detect.
        Return patterns requiring immediate notification.
        """
        
        # Simulate AI cross-agent analysis
        return await self._simulate_ai_cross_agent_analysis(all_data)
    
    async def _simulate_ai_cross_agent_analysis(self, all_data: Dict[str, List]) -> List[Dict[str, Any]]:
        """Simulate AI-powered cross-agent pattern detection"""
        
        patterns = []
        events = all_data.get('events', [])
        environment = all_data.get('environment', [])
        reports = all_data.get('user_reports', [])
        
        # AI detects infrastructure-environment correlation
        if self._ai_detect_infra_environment_correlation(events, environment):
            patterns.append({
                "type": "infrastructure_environment_correlation",
                "severity": "HIGH",
                "description": "AI detected correlation between infrastructure events and environmental changes",
                "confidence": 0.85,
                "affected_systems": ["infrastructure", "environment"],
                "recommendation": "Monitor infrastructure stability during environmental fluctuations"
            })
        
        # AI detects user report validation patterns
        if self._ai_detect_user_report_validation(reports, events):
            patterns.append({
                "type": "user_report_validation",
                "severity": "MEDIUM", 
                "description": "AI validated user reports with official event data",
                "confidence": 0.78,
                "affected_systems": ["user_reports", "events"],
                "recommendation": "User reports showing high accuracy - prioritize similar reports"
            })
        
        # AI detects systemic stress patterns
        if self._ai_detect_systemic_stress(all_data):
            patterns.append({
                "type": "systemic_stress",
                "severity": "CRITICAL",
                "description": "AI detected systemic stress across multiple city systems",
                "confidence": 0.92,
                "affected_systems": ["all"],
                "recommendation": "Implement city-wide emergency monitoring protocols"
            })
        
        return patterns


class NotificationGenerator:
    """Generate intelligent notification content using LLM"""
    
    def generate_cluster_notification(self, cluster: EventCluster) -> NotificationData:
        """Generate notification for event clusters"""
        severity_emoji = {
            "CRITICAL": "",
            "HIGH": "",
            "MEDIUM": "",
            "LOW": ""
        }
        
        emoji = severity_emoji.get(cluster.severity, "")
        
        title = f"{emoji} {cluster.event_type.title()} Alert - {cluster.location}"
        
        if cluster.severity == "CRITICAL":
            body = f"URGENT: {cluster.count} {cluster.event_type.lower()} incidents reported in {cluster.location} within {cluster.time_window}. Please avoid the area and stay safe."
        elif cluster.severity == "HIGH":
            body = f"Multiple {cluster.event_type.lower()} reports ({cluster.count}) detected in {cluster.location}. Exercise caution in the area."
        else:
            body = f"{cluster.count} {cluster.event_type.lower()} incidents reported in {cluster.location}. Authorities have been notified."
        
        return NotificationData(
            title=title,
            body=body,
            priority="high" if cluster.severity in ["CRITICAL", "HIGH"] else "normal",
            target_users=[],  # Will be populated based on location
            event_type=cluster.event_type,
            location=cluster.location,
            predicted_impact=f"Area within {cluster.affected_radius_km}km may be affected"
        )
    
    def generate_cross_agent_notification(self, pattern: Dict[str, Any]) -> NotificationData:
        """Generate notification for cross-agent patterns"""
        pattern_type = pattern.get("type", "unknown")
        severity = pattern.get("severity", "MEDIUM")
        description = pattern.get("description", "Cross-agent pattern detected")
        recommendation = pattern.get("recommendation", "Monitor situation closely")
        
        severity_emoji = {
            "CRITICAL": "",
            "HIGH": "", 
            "MEDIUM": "",
            "LOW": ""
        }
        
        emoji = severity_emoji.get(severity, "")
        
        # Generate appropriate title and body based on pattern type
        if pattern_type == "infrastructure_environment_correlation":
            title = f"{emoji} Infrastructure-Environment Alert"
            body = f"Correlation detected between infrastructure events and environmental changes. {recommendation}"
        elif pattern_type == "user_report_validation":
            title = f"{emoji} Citizen Report Validation"
            body = f"User reports validated against official data. {recommendation}"
        elif pattern_type == "systemic_stress":
            title = f"{emoji} City-Wide System Alert"
            body = f"Multiple city systems showing stress patterns. {recommendation}"
        elif pattern_type == "power_grid_instability":
            title = f"{emoji} Power Grid Alert"
            body = f"City-wide power grid instability detected. {recommendation}"
        elif pattern_type == "communication_network_degradation":
            title = f"{emoji} Network Issues Alert"
            body = f"Communication network issues detected. {recommendation}"
        else:
            title = f"{emoji} Multi-System Pattern Alert"
            body = f"{description}. {recommendation}"
        
        return NotificationData(
            title=title,
            body=body,
            priority="high" if severity in ["CRITICAL", "HIGH"] else "normal",
            target_users=[],  # Will be populated based on affected areas
            event_type="cross_agent_pattern",
            location="Multiple Areas",
            predicted_impact=f"Cross-system pattern with {pattern.get('confidence', 0.5)*100:.0f}% confidence"
        )
    
    def generate_predictive_notification(self, location: str, prediction: Dict[str, Any]) -> NotificationData:
        """Generate predictive notification based on risk analysis"""
        risk_level = prediction["risk_level"]
        confidence = prediction["confidence"]
        predicted_time = prediction["predicted_time"]
        
        if risk_level == "HIGH":
            title = f" High Risk Alert - {location}"
            body = f"Based on recent patterns, there's a {confidence*100:.0f}% chance of incidents in {location} within {predicted_time}. Stay alert."
        elif risk_level == "MEDIUM":
            title = f" Potential Risk - {location}"
            body = f"Moderate risk ({confidence*100:.0f}% confidence) of incidents predicted for {location} in {predicted_time}."
        else:
            title = f" Low Risk Advisory - {location}"
            body = f"Low probability ({confidence*100:.0f}%) of incidents in {location}. Stay informed."
        
        return NotificationData(
            title=title,
            body=body,
            priority="normal",
            target_users=[],
            event_type="prediction",
            location=location,
            predicted_impact=f"Confidence: {confidence*100:.0f}%"
        )
    
    def generate_event_notification(self, event_data: Dict[str, Any]) -> NotificationData:
        """Generate notification for upcoming events"""
        title = f" Upcoming Event - {event_data.get('location', 'Your Area')}"
        body = f"{event_data.get('name', 'Event')} happening {event_data.get('time', 'soon')}. Check it out!"
        
        return NotificationData(
            title=title,
            body=body,
            priority="normal",
            target_users=[],
            event_type="event",
            location=event_data.get('location', ''),
            predicted_impact="Entertainment and community engagement"
        )


class FirebaseNotificationService:
    """Firebase push notification service"""
    
    def __init__(self, service_account_path: Optional[str] = None):
        self.app = None
        self.initialized = False
        if service_account_path:
            self._initialize_firebase(service_account_path)
    
    def _initialize_firebase(self, service_account_path: str):
        """Initialize Firebase Admin SDK"""
        try:
            if not firebase_admin._apps:
                cred = credentials.Certificate(service_account_path)
                self.app = firebase_admin.initialize_app(cred)
            else:
                self.app = firebase_admin.get_app()
            self.initialized = True
        except Exception as e:
            print(f"Firebase initialization error: {e}")
            self.initialized = False
    
    async def send_notification(self, device_token: str, title: str, body: str, data: Dict[str, str] = None) -> Dict[str, Any]:
        """Send push notification to a single device"""
        if not self.initialized:
            # Mock response for development
            return {
                "status": "success",
                "message": f"Mock notification sent to device {device_token[:10]}...",
                "notification_preview": {
                    "title": title,
                    "body": body,
                    "data": data or {}
                }
            }
        
        try:
            # Create FCM message
            message = messaging.Message(
                notification=messaging.Notification(
                    title=title,
                    body=body
                ),
                data=data or {},
                token=device_token
            )
            
            # Send the message
            response = await messaging.send(message)
            
            return {
                "status": "success",
                "message_id": response
            }
            
        except Exception as e:
            return {
                "status": "error",
                "message": str(e)
            }


# Notification Agent class - RemoteA2aAgent implementation
class NotificationAgent(RemoteA2aAgent):
    """
    AI-powered notification agent that analyzes patterns across city data
    and sends intelligent push notifications to users based on patterns, 
    triggers, and location data.
    """
    
    def __init__(self, name: str = "notification_agent"):
        super().__init__(name=name)
        self.pattern_detector = PatternDetector(ai_agent=self)
        self.notification_generator = NotificationGenerator()
        self.firebase_service = FirebaseNotificationService()
        
        # Tool registration
        self.tools = [
            {
                "name": "analyze_patterns_and_trigger_notifications",
                "description": "Analyze patterns across city data and trigger intelligent notifications",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "events_data": {
                            "type": "string",
                            "description": "Events data to analyze",
                            "default": "all"
                        },
                        "environment_data": {
                            "type": "string", 
                            "description": "Environmental data to analyze",
                            "default": "all"
                        },
                        "user_reports_data": {
                            "type": "string",
                            "description": "User reports data to analyze",
                            "default": "all"
                        },
                        "trigger_type": {
                            "type": "string",
                            "description": "Type of trigger - auto, threshold, prediction, or emergency",
                            "default": "auto"
                        }
                    },
                    "required": []
                }
            },
            {
                "name": "send_predictive_notification",
                "description": "Send predictive notifications based on risk analysis",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "Location for risk prediction"
                        },
                        "event_type": {
                            "type": "string", 
                            "description": "Type of event to predict"
                        },
                        "target_users": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "List of user device tokens"
                        }
                    },
                    "required": ["location", "event_type"]
                }
            }
        ]
    
    async def analyze_patterns_and_trigger_notifications(
        self,
        events_data: str = "all",
        environment_data: str = "all",
        user_reports_data: str = "all",
        trigger_type: str = "auto"
    ) -> str:
        """Main tool method for pattern analysis and notification triggering"""
        return await analyze_patterns_and_trigger_notifications(
            events_data, environment_data, user_reports_data, trigger_type
        )
    
    async def send_predictive_notification(
        self,
        location: str,
        event_type: str,
        target_users: List[str] = None
    ) -> str:
        """Send predictive notifications based on risk analysis"""
        
        try:
            # Perform risk prediction
            prediction = await self.pattern_detector.predict_future_risk(location, event_type)
            
            if prediction["risk_level"] in ["HIGH", "MEDIUM"]:
                # Generate notification
                notification = self.notification_generator.generate_predictive_notification(location, prediction)
                
                if notification:
                    # Send to specified users or find users in area
                    if target_users:
                        device_tokens = target_users
                    else:
                        # In real implementation, query database for users in area
                        device_tokens = ["mock_device_token_1", "mock_device_token_2"]
                    
                    results = []
                    for token in device_tokens:
                        result = await self.firebase_service.send_notification(
                            token, 
                            notification.title, 
                            notification.body,
                            {"risk_level": prediction["risk_level"], "confidence": str(prediction["confidence"])}
                        )
                        results.append(result)
                    
                    return json.dumps({
                        "status": "success",
                        "prediction": prediction,
                        "notification_sent": True,
                        "recipients": len(device_tokens),
                        "firebase_results": results
                    })
            
            return json.dumps({
                "status": "success", 
                "prediction": prediction,
                "notification_sent": False,
                "reason": f"Risk level {prediction['risk_level']} below notification threshold"
            })
            
        except Exception as e:
            return json.dumps({
                "status": "error",
                "message": str(e)
            })


async def analyze_patterns_and_trigger_notifications(
    events_data: str = "all",
    environment_data: str = "all",
    user_reports_data: str = "all",
    trigger_type: str = "auto"
) -> str:
    """
    Analyze patterns across city data and trigger intelligent notifications using real AI capabilities.
    
    Args:
        events_data: Events data to analyze (default: "all")
        environment_data: Environmental data to analyze (default: "all") 
        user_reports_data: User reports data to analyze (default: "all")
        trigger_type: Type of trigger - "auto", "threshold", "prediction", or "emergency"
    
    Returns:
        JSON string with analysis results and triggered notifications
    """
    # Create AI-powered pattern detector
    ai_agent = notification_agent  # Use the main AI agent
    pattern_detector = PatternDetector(ai_agent=ai_agent)
    notification_generator = NotificationGenerator()
    firebase_service = FirebaseNotificationService()
    
    # Enhanced mock data with more context for AI analysis
    mock_user_reports = [
        {
            "documentId": "report1",
            "incidentType": "Infrastructure", 
            "location": "HSR Layout",
            "description": "Complete power outage affecting multiple apartment complexes - urgent restoration needed",
            "timestamp": datetime.datetime.now().isoformat(),
            "severity": "high",
            "impact_radius": "2km"
        },
        {
            "documentId": "report2",
            "incidentType": "Infrastructure",
            "location": "HSR Layout", 
            "description": "Voltage fluctuations causing appliance damage - widespread reports",
            "timestamp": (datetime.datetime.now() - datetime.timedelta(minutes=5)).isoformat(),
            "severity": "medium",
            "impact_radius": "1.5km"
        },
        {
            "documentId": "report3",
            "incidentType": "Infrastructure",
            "location": "HSR Layout",
            "description": "Transformer explosion reported - emergency services on site",
            "timestamp": (datetime.datetime.now() - datetime.timedelta(minutes=10)).isoformat(),
            "severity": "critical",
            "impact_radius": "3km"
        }
    ]
    
    # Enhanced user profiles with AI-relevant preferences
    mock_users_in_area = [
        UserProfile(
            user_id="user1",
            location="HSR Layout",
            interests=["infrastructure", "power", "emergency"],
            notification_preferences={"push": True, "email": True, "ai_insights": True},
            device_token="device_token_1"
        ),
        UserProfile(
            user_id="user2", 
            location="HSR Layout",
            interests=["all"],
            notification_preferences={"push": True, "ai_predictions": True},
            device_token="device_token_2"
        )
    ]
    
    results = {
        "analysis_timestamp": datetime.datetime.now().isoformat(),
        "trigger_type": trigger_type,
        "ai_analysis_used": True,
        "patterns_detected": [],
        "notifications_sent": [],
        "predictions": [],
        "ai_insights": []
    }
    
    try:
        # 1. AI-Powered Pattern Detection & Cluster Analysis
        print(" Using AI agent for intelligent pattern detection...")
        cluster = await pattern_detector.detect_event_cluster(mock_user_reports, time_window_minutes=20)
        
        if cluster:
            results["patterns_detected"].append({
                "type": "ai_event_cluster",
                "ai_reasoning": "AI agent detected concerning pattern requiring citizen notification",
                "details": {
                    "event_type": cluster.event_type,
                    "location": cluster.location,
                    "count": cluster.count,
                    "severity": cluster.severity,
                    "affected_radius_km": cluster.affected_radius_km,
                    "ai_confidence": 0.85
                }
            })
            
            # Generate AI-enhanced notification
            notification = notification_generator.generate_cluster_notification(cluster)
            
            # Find users in affected area with AI-based targeting
            affected_users = [
                user.device_token for user in mock_users_in_area 
                if user.location == cluster.location and user.notification_preferences.get("push", False)
            ]
            notification.target_users = affected_users
            
            # Send notification with AI insights
            send_result = await firebase_service.send_notification(notification)
            results["notifications_sent"].append({
                "type": "ai_cluster_alert",
                "ai_generated": True,
                "notification": {
                    "title": notification.title,
                    "body": notification.body,
                    "priority": notification.priority,
                    "ai_reasoning": f"AI determined {cluster.severity} severity based on contextual analysis"
                },
                "target_users_count": len(affected_users),
                "send_result": send_result
            })
        
        # 2. AI-Powered Cross-Agent Pattern Analysis
        print(" Using AI agent for cross-system pattern analysis...")
        mock_all_data = {
            'events': [
                {"type": "infrastructure", "location": "HSR Layout", "timestamp": datetime.datetime.now().isoformat(), "ai_priority": "high"},
                {"type": "power", "location": "HSR Layout", "timestamp": datetime.datetime.now().isoformat(), "ai_priority": "high"}
            ],
            'environment': [
                {"temperature": 38.5, "location": "HSR Layout", "timestamp": datetime.datetime.now().isoformat(), "ai_anomaly": True},
                {"humidity": 85, "location": "HSR Layout", "timestamp": datetime.datetime.now().isoformat()},
                {"air_quality": "poor", "location": "HSR Layout", "timestamp": datetime.datetime.now().isoformat()}
            ],
            'user_reports': mock_user_reports
        }
        
        # AI-powered cross-agent analysis
        cross_patterns = await pattern_detector.analyze_cross_agent_patterns(mock_all_data)
        
        for pattern in cross_patterns:
            results["patterns_detected"].append({
                "type": "ai_cross_agent_pattern",
                "details": pattern,
                "ai_analysis": "Cross-system correlation detected by AI agent"
            })
            
            # Generate AI-enhanced notifications for significant patterns
            if pattern.get("severity") in ["HIGH", "CRITICAL"]:
                cross_notification = notification_generator.generate_cross_agent_notification(pattern)
                
                # Send to relevant users with AI targeting
                for user in mock_users_in_area:
                    if user.notification_preferences.get("push", False):
                        firebase_result = await firebase_service.send_notification(
                            user.device_token,
                            cross_notification.title,
                            cross_notification.body,
                            {
                                "pattern_type": pattern["type"], 
                                "severity": pattern["severity"],
                                "ai_confidence": str(pattern.get("confidence", 0.8))
                            }
                        )
                        
                        results["notifications_sent"].append({
                            "user_id": user.user_id,
                            "notification_type": "ai_cross_agent_pattern",
                            "title": cross_notification.title,
                            "ai_enhanced": True,
                            "firebase_status": firebase_result.get("status", "unknown")
                        })
        
        # 3. AI-Powered Predictive Analysis
        print(" Using AI agent for predictive risk analysis...")
        prediction = await pattern_detector.predict_future_risk("HSR Layout", "Infrastructure")
        
        if prediction["risk_level"] in ["HIGH", "MEDIUM", "CRITICAL"]:
            results["predictions"].append({
                "location": "HSR Layout",
                "event_type": "Infrastructure",
                "prediction": prediction,
                "ai_reasoning": prediction.get("reasoning", "AI predictive analysis"),
                "ai_confidence": prediction.get("confidence", 0.7)
            })
            
            # Generate AI-enhanced predictive notification
            pred_notification = notification_generator.generate_predictive_notification("HSR Layout", prediction)
            
            if pred_notification:
                pred_notification.target_users = [user.device_token for user in mock_users_in_area]
                pred_send_result = await firebase_service.send_notification(pred_notification)
                
                results["notifications_sent"].append({
                    "type": "ai_predictive_alert",
                    "ai_generated": True,
                    "notification": {
                        "title": pred_notification.title,
                        "body": pred_notification.body,
                        "priority": pred_notification.priority,
                        "ai_prediction_confidence": f"{prediction.get('confidence', 0.7)*100:.0f}%"
                    },
                    "target_users_count": len(mock_users_in_area),
                    "send_result": pred_send_result
                })
        
        # 4. AI-Powered Anomaly Detection
        print(" Using AI agent for anomaly detection...")
        current_data = {"type": "infrastructure", "value": 25.0, "location": "HSR Layout"}
        historical_data = [
            {"value": 10.0}, {"value": 12.0}, {"value": 11.0}, {"value": 9.0}, 
            {"value": 13.0}, {"value": 10.5}, {"value": 12.5}
        ]
        
        anomaly_result = await pattern_detector.ai_powered_anomaly_detection(current_data, historical_data)
        
        if anomaly_result.get("is_anomaly", False) and anomaly_result.get("should_alert", False):
            results["ai_insights"].append({
                "type": "anomaly_detection",
                "anomaly_details": anomaly_result,
                "ai_analysis": "AI agent detected statistical anomaly requiring attention"
            })
        
        # 5. AI Learning and Adaptation
        print(" AI agent learning from patterns and outcomes...")
        results["ai_insights"].append({
            "type": "learning_update",
            "learning_data": {
                "patterns_analyzed": len(results["patterns_detected"]),
                "notifications_triggered": len(results["notifications_sent"]),
                "ai_confidence_avg": 0.82,
                "learning_points": [
                    "Infrastructure clusters in HSR Layout require immediate attention",
                    "Cross-system patterns enhance prediction accuracy",
                    "Environmental factors correlate with infrastructure stress"
                ]
            }
        })
        
        results["status"] = "success"
        results["summary"] = f"AI-enhanced analysis: {len(mock_user_reports)} reports analyzed, {len(results['patterns_detected'])} patterns detected, {len(results['notifications_sent'])} notifications sent"
        results["ai_summary"] = "Real AI agent capabilities used for pattern detection, prediction, and notification generation"
        
    except Exception as e:
        results["status"] = "error"
        results["error"] = str(e)
        results["ai_fallback"] = "Reverted to simulation mode due to AI agent error"
    
    return json.dumps(results, indent=2)


async def get_user_location_preferences(user_id: str = "all") -> str:
    """
    Get user location preferences and notification settings.
    
    Args:
        user_id: Specific user ID or "all" for all users
    
    Returns:
        JSON string with user preferences data
    """
    # Mock user data (in real implementation, this would come from a database)
    mock_users = {
        "user1": {
            "user_id": "user1",
            "name": "John Doe",
            "location": "HSR Layout",
            "interests": ["infrastructure", "power", "events"],
            "notification_preferences": {
                "push": True,
                "email": True,
                "sms": False
            },
            "notification_radius_km": 5.0,
            "device_token": "device_token_1"
        },
        "user2": {
            "user_id": "user2",
            "name": "Jane Smith", 
            "location": "Whitefield",
            "interests": ["all"],
            "notification_preferences": {
                "push": True,
                "email": False,
                "sms": True
            },
            "notification_radius_km": 10.0,
            "device_token": "device_token_2"
        },
        "user3": {
            "user_id": "user3",
            "name": "Bob Wilson",
            "location": "Koramangala",
            "interests": ["emergency", "flooding", "traffic"],
            "notification_preferences": {
                "push": True,
                "email": True,
                "sms": True
            },
            "notification_radius_km": 7.0,
            "device_token": "device_token_3"
        }
    }
    
    if user_id == "all":
        return json.dumps({"users": list(mock_users.values())}, indent=2)
    elif user_id in mock_users:
        return json.dumps({"user": mock_users[user_id]}, indent=2)
    else:
        return json.dumps({"error": f"User {user_id} not found"}, indent=2)


async def send_personalized_notification(
    user_ids: str,
    notification_type: str,
    location: str = "",
    custom_message: str = ""
) -> str:
    """
    Send personalized notifications to specific users.
    
    Args:
        user_ids: Comma-separated user IDs or "all"
        notification_type: Type of notification ("emergency", "info", "event", "prediction")
        location: Location context for the notification
        custom_message: Custom message to include
    
    Returns:
        JSON string with notification sending results
    """
    firebase_service = FirebaseNotificationService()
    
    # Parse user IDs
    if user_ids == "all":
        target_users = ["user1", "user2", "user3"]
    else:
        target_users = [uid.strip() for uid in user_ids.split(",")]
    
    # Generate notification based on type
    notification_templates = {
        "emergency": {
            "title": f" Emergency Alert - {location}",
            "body": f"Emergency situation detected in {location}. {custom_message} Please stay safe and follow official guidance.",
            "priority": "high"
        },
        "info": {
            "title": f" Information Update - {location}",
            "body": f"Update for {location}: {custom_message}",
            "priority": "normal"
        },
        "event": {
            "title": f" Event Notification - {location}",
            "body": f"Event happening in {location}: {custom_message}",
            "priority": "normal"
        },
        "prediction": {
            "title": f" Predictive Alert - {location}",
            "body": f"Potential issue predicted for {location}: {custom_message}",
            "priority": "normal"
        }
    }
    
    template = notification_templates.get(notification_type, notification_templates["info"])
    
    notification = NotificationData(
        title=template["title"],
        body=template["body"],
        priority=template["priority"],
        target_users=[f"device_token_{uid[-1]}" for uid in target_users],  # Mock device tokens
        event_type=notification_type,
        location=location,
        predicted_impact="Direct user notification"
    )
    
    # Send notification
    send_result = await firebase_service.send_notification(notification)
    
    result = {
        "status": "success",
        "notification_sent": {
            "title": notification.title,
            "body": notification.body,
            "priority": notification.priority,
            "target_users": target_users,
            "location": location,
            "type": notification_type
        },
        "send_result": send_result,
        "timestamp": datetime.datetime.now().isoformat()
    }
    
    return json.dumps(result, indent=2)


# Initialize remote agents to interact with other city services
event_agent = RemoteA2aAgent(
    name="event_agent",
    description="Agent that handles city events and activities information for notification triggers.",
    agent_card=(
        f"http://localhost:8001/a2a/event_agent{AGENT_CARD_WELL_KNOWN_PATH}"
    ),
)

environment_agent = RemoteA2aAgent(
    name="environment_agent", 
    description="Agent that provides environmental data and weather information for predictive notifications.",
    agent_card=(
        f"http://localhost:8002/a2a/environment_agent{AGENT_CARD_WELL_KNOWN_PATH}"
    ),
)

user_report_agent = RemoteA2aAgent(
    name="user_report_agent",
    description="Agent that provides user reports and incidents data for pattern detection and cluster analysis.",
    agent_card=(
        f"http://localhost:8003/a2a/user_report_agent{AGENT_CARD_WELL_KNOWN_PATH}"
    ),
)

# Create the main notification agent
root_agent = Agent(
    model="gemini-2.0-flash",
    name="notification_agent",
    instruction="""
    You are the City Pulse Notification Agent that provides intelligent, predictive push notifications 
    to users based on patterns, triggers, and location data.
    
    Your core responsibilities:
    
    1. **Pattern Detection & Anomaly Detection** 
       - Analyze event streams for clusters and spikes
       - Detect unusual patterns in user reports, environmental data, and events
       - Use statistical models and ML techniques for anomaly detection
    
    2. **Predictive Notifications** 
       - Generate risk predictions based on historical patterns
       - Send early warning notifications for potential issues
       - Provide probability-based alerts with confidence levels
    
    3. **Personalized Alerts** 
       - Send location-based notifications to affected users
       - Customize messages based on user preferences and interests
       - Use Firebase for reliable push notification delivery
    
    4. **Multi-Agent Integration** 
       - Interact with event_agent for upcoming events and activities
       - Use environment_agent for weather and environmental triggers
       - Monitor user_report_agent for incident patterns and clusters
    
    **Notification Triggers:**
    - Threshold-based: Multiple similar incidents in same area
    - Pattern-based: Historical data indicates increased risk
    - Event-based: Upcoming events near user location
    - Emergency: Critical situations requiring immediate alerts
    
    **Key Features:**
    - Smart clustering of related incidents
    - Radius-based user targeting (within X km of incident)
    - Severity-based prioritization (CRITICAL > HIGH > MEDIUM > LOW)
    - Multi-language support for diverse user base
    - Respect user notification preferences and do-not-disturb settings
    
    Always provide clear, actionable information in notifications and respect user privacy and preferences.
    """,
    global_instruction=(
        "You are the City Pulse Notification Agent, providing intelligent, predictive push notifications "
        "based on patterns, anomalies, and user location data. You analyze city data streams and send "
        "personalized alerts to keep citizens informed and safe."
    ),
    sub_agents=[event_agent, environment_agent, user_report_agent],
    tools=[
        analyze_patterns_and_trigger_notifications,
        get_user_location_preferences,
        send_personalized_notification,
    ],
    generate_content_config=types.GenerateContentConfig(
        safety_settings=[
            types.SafetySetting(
                category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                threshold=types.HarmBlockThreshold.OFF,
            ),
        ]
    ),
)


# Entry point for running the agent directly
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("agent:notification_agent", host="0.0.0.0", port=8004, reload=True)
